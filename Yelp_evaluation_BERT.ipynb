{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Yelp-evaluation_BERT.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ZfFofRq00h1v",
        "_wHxJJ3zu-1P",
        "MwQzlm6D4gja",
        "0YAQ7HtH27K1",
        "gO-y1nO2-WY2",
        "Q6gGGa7V_aNE"
      ],
      "authorship_tag": "ABX9TyO7HJYIayjZJu/zVeEN5762",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lupis30puc/yelp_bert_random_forest/blob/update-6/Yelp_evaluation_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfFofRq00h1v"
      },
      "source": [
        "## Set Up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJD0FGBS0ghp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d73d100-5299-492f-b706-6b1dfe925531"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/b1/41130a228dd656a1a31ba281598a968320283f48d42782845f6ba567f00b/transformers-4.2.2-py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 7.7MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 35.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.4.0)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 50.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=e773bf42a8bcdb36b5f540defbf95a277910e21458abd3e4d0455c5c8ee28d48\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fJjJCGQ0lVf"
      },
      "source": [
        "## GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfLHT8dI0qQQ",
        "outputId": "e88d1e38-6be0-4d3d-8e20-24f8871dad6a"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWxJt3i20tLd",
        "outputId": "6f75f5c7-2324-47db-b214-cc36af2f485a"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9QoEyD40yWw"
      },
      "source": [
        "## Loading the tensors dataset and model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3H3o99g0vn4",
        "outputId": "be160b0c-b1c7-4f6b-82f7-f3c81af54115"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBCut10VzcJj"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import pickle"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xU8egMBY1A6Q"
      },
      "source": [
        "with open('/content/drive/MyDrive/Yelp/tensors_yelp/test_ids_128.pkl', 'rb') as f:\n",
        "    test_ids = pickle.load(f)\n",
        "\n",
        "with open('/content/drive/MyDrive/Yelp/tensors_yelp/train_ids_128.pkl', 'rb') as v:\n",
        "    train_ids = pickle.load(v)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVdGHY_Qrxxr"
      },
      "source": [
        "with open('/content/drive/MyDrive/Yelp/tensors_yelp/test_ids_99.pkl', 'rb') as f:\n",
        "    test_ids_99 = pickle.load(f)\n",
        "\n",
        "with open('/content/drive/MyDrive/Yelp/tensors_yelp/train_ids_99.pkl', 'rb') as v:\n",
        "    train_ids_99 = pickle.load(v)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wV_0pXBtbQPd"
      },
      "source": [
        "train_dataset = torch.load('/content/drive/MyDrive/Yelp/tensors_yelp/_train_128')\n",
        "test_dataset = torch.load('/content/drive/MyDrive/Yelp/tensors_yelp/_test_128')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0ZDnHpxr4ub"
      },
      "source": [
        "train_dataset_99 = torch.load('/content/drive/MyDrive/Yelp/tensors_yelp/_train_99')\n",
        "test_dataset_99 = torch.load('/content/drive/MyDrive/Yelp/tensors_yelp/_test_99')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvA9mRKx1yMx",
        "outputId": "756dcb1c-5d60-4dac-dd95-351db126fb57"
      },
      "source": [
        "train_dataset[0]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([  101,  2117,  2190,  4770,  5869,  7136,  3477, 10797,  2154,  4392,\n",
              "          2058, 18098,  6610,  2094,  8974,  4978,  8479,  7492,  2180,  2292,\n",
              "          3288,  6544,  3835,  4638, 12679,  4569,  5541,  4268,  2926,  6001,\n",
              "          2300,  7358, 21881, 12403, 19091,  2080,  3492,  5151,   102,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0]),\n",
              " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " tensor(1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVTiBYjM3kri",
        "outputId": "75374b53-52d9-4f86-8f89-020358992e14"
      },
      "source": [
        "train_dataset_99[0]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([  101,  2117,  2190,  4770,  5869,  7136,  3477, 10797,  2154,  4392,\n",
              "          2058, 18098,  6610,  2094,  8974,  4978,  8479,  7492,  2180,  2292,\n",
              "          3288,  6544,  3835,  4638, 12679,  4569,  5541,  4268,  2926,  6001,\n",
              "          2300,  7358, 21881, 12403, 19091,  2080,  3492,  5151,   102,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0]),\n",
              " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0]),\n",
              " tensor(1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zn4lFOdd10m0"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "# batch size\n",
        "batch_size = 32\n",
        "\n",
        "train_sampler = SequentialSampler(train_dataset)\n",
        "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "prediction_sampler = SequentialSampler(test_dataset)\n",
        "prediction_dataloader = DataLoader(test_dataset, sampler=prediction_sampler, batch_size=batch_size)\n",
        "\n",
        "train_sampler_99 = SequentialSampler(train_dataset_99)\n",
        "train_dataloader_99 = DataLoader(train_dataset_99, sampler=train_sampler_99, batch_size=batch_size)\n",
        "\n",
        "prediction_sampler_99 = SequentialSampler(test_dataset_99)\n",
        "prediction_dataloader_99 = DataLoader(test_dataset_99, sampler=prediction_sampler_99, batch_size=batch_size)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wHxJJ3zu-1P"
      },
      "source": [
        "### Initializing the models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_HVuNEW2Hld",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "804126e3-9c7b-4318-fa15-769dcdd58a4e"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "device = torch.device(\"cuda\")\n",
        "#model = TheModelClass(*args, **kwargs)\n",
        "\"\"\"\n",
        "model = BertForSequenceClassification(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\"\"\"\n",
        "model = torch.load('/content/drive/MyDrive/Yelp/model_128/model-31-JAN_3e', map_location=\"cuda:0\")  # Choose whatever GPU device number you want\n",
        "model.to(device)\n",
        "# Make sure to call input = input.to(device) on any input tensors that you feed to the model\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrD_EYTvjr5B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24b30373-2340-43db-fedc-730d76ac83db"
      },
      "source": [
        "device2 = torch.device(\"cuda\")\n",
        "#model = TheModelClass(*args, **kwargs)\n",
        "\"\"\"\n",
        "model = BertForSequenceClassification(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\"\"\"\n",
        "model2 = torch.load('/content/drive/MyDrive/Yelp/model_99/model-25-JAN_3e', map_location=\"cuda:0\")  # Choose whatever GPU device number you want\n",
        "model2.to(device2)\n",
        "# Make sure to call input = input.to(device) on any input tensors that you feed to the model\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epOKQge4_JHw"
      },
      "source": [
        "## Evaluating the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87L9jZ42ty7a"
      },
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "    #np.argmax(logits, axis=1).flatten()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eejT6EvdJ2B5"
      },
      "source": [
        "Evaluating the test dataset with the model of max_length 128:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBgU8-q048iy",
        "outputId": "227af95e-65a8-4bb3-a074-6458c04dc4ba"
      },
      "source": [
        "%%time\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=b_input_mask, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "\n",
        "#logits = logits[0].detach().cpu().numpy()\n",
        "\n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    DONE.\n",
            "CPU times: user 9.65 s, sys: 7.41 s, total: 17.1 s\n",
            "Wall time: 17.2 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZFdNdnwhNtY"
      },
      "source": [
        "from torch.nn import functional as F\n",
        "loss = F.cross_entropy(outputs.logits, b_labels)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__TqgD5bhWnX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7359888-a4d8-4180-d747-0d038a5e3924"
      },
      "source": [
        "loss"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0062, device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCOCmnl3hhNg"
      },
      "source": [
        "loss.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nt12q-Pzu-dz",
        "outputId": "4e4f6a99-40f8-4985-e579-965e0864155a"
      },
      "source": [
        "#test\n",
        "total_eval_accuracy = 0\n",
        "for i in range(len(predictions)):\n",
        "  total_eval_accuracy += flat_accuracy(predictions[i], true_labels[i])\n",
        "print(total_eval_accuracy)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "75.15625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZevst2b0Goo",
        "outputId": "08048260-7cbe-4b81-d1a1-7ee402f2a2c8"
      },
      "source": [
        "#test\n",
        "avg_val_accuracy = total_eval_accuracy / len(prediction_dataloader)\n",
        "print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.92\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSj0Y1-Hzp0u",
        "outputId": "5dd251fb-bb45-42e4-b58b-168cd968e158"
      },
      "source": [
        "#test\n",
        "pred_flat = np.argmax(predictions[0], axis=1).flatten()\n",
        "labels_flat = true_labels[0].flatten()\n",
        "tot_ev_acc = np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "print(tot_ev_acc)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.84375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHLoSmqSKLgj"
      },
      "source": [
        "Evaluating the test dataset with the model of max_length 99:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1m9rFjHsliy",
        "outputId": "9c4c3b2e-922c-450f-b30e-0c50379973b1"
      },
      "source": [
        "%%time\n",
        "# Put model in evaluation mode\n",
        "model2.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions2 , true_labels2 = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader_99:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids_99, b_input_mask_99, b_labels_99 = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs_99 = model2(b_input_ids_99, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask_99)\n",
        "\n",
        "  logits_99 = outputs_99[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits_99 = logits_99.detach().cpu().numpy()\n",
        "  label_ids_99 = b_labels_99.to('cpu').numpy()\n",
        "  \n",
        "\n",
        "#logits = logits[0].detach().cpu().numpy()\n",
        "\n",
        "  # Store predictions and true labels\n",
        "  predictions2.append(logits_99)\n",
        "  true_labels2.append(label_ids_99)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    DONE.\n",
            "CPU times: user 7.95 s, sys: 5.87 s, total: 13.8 s\n",
            "Wall time: 13.8 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ypqBCNpuMrX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3c6977b-0ca9-418e-9a7b-111ceca3a507"
      },
      "source": [
        "from torch.nn import functional as F\n",
        "loss_99 = F.cross_entropy(outputs_99.logits, b_labels_99)\n",
        "loss_99"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0040, device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjkcF81DP7w-",
        "outputId": "c812ef86-71f2-4342-9c05-fe4efefd1cb4"
      },
      "source": [
        "#test\n",
        "total_eval_accuracy_99 = 0\n",
        "for i in range(len(predictions2)):\n",
        "  total_eval_accuracy_99 += flat_accuracy(predictions2[i], true_labels2[i])\n",
        "print(total_eval_accuracy_99)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "75.21875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZY1BU4rxP7w_",
        "outputId": "626d836d-5e33-4df3-d028-0ad98e9222b0"
      },
      "source": [
        "#test\n",
        "avg_val_accuracy_99 = total_eval_accuracy_99 / len(prediction_dataloader_99)\n",
        "print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy_99))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.92\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zw3NJFpUP7xA",
        "outputId": "a3c15cab-0ade-460b-96c9-e85e9a85f173"
      },
      "source": [
        "#test\n",
        "pred_flat2 = np.argmax(predictions2[0], axis=1).flatten()\n",
        "labels_flat2 = true_labels2[0].flatten()\n",
        "tot_ev_acc2 = np.sum(pred_flat2 == labels_flat2) / len(labels_flat2)\n",
        "print(tot_ev_acc2)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.84375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68iSi1bKsmI7"
      },
      "source": [
        "Evaluating the train dataset with the model of max_length 128:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxdxpvDl4oVZ",
        "outputId": "7ae8c499-23c3-41f2-feb7-4d40456e9eba"
      },
      "source": [
        "%%time\n",
        "# Tracking variables \n",
        "predictions_tr , true_labels_tr = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in train_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids_tr, b_input_mask_tr, b_labels_tr = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs_tr = model(b_input_ids_tr, token_type_ids=b_input_mask_tr, \n",
        "                      attention_mask=b_input_mask_tr)\n",
        "      \n",
        "  logits_tr = outputs_tr[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits_tr = logits_tr.detach().cpu().numpy()\n",
        "  label_ids_tr = b_labels_tr.to('cpu').numpy()\n",
        "  \n",
        "\n",
        "#logits = logits[0].detach().cpu().numpy()\n",
        "\n",
        "  # Store predictions and true labels\n",
        "  predictions_tr.append(logits_tr)\n",
        "  true_labels_tr.append(label_ids_tr)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    DONE.\n",
            "CPU times: user 39.9 s, sys: 30.2 s, total: 1min 10s\n",
            "Wall time: 1min 10s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOuuxYUkidpt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf789fb4-56c0-48ee-bad8-dd77b0382c04"
      },
      "source": [
        "loss_tr = F.cross_entropy(outputs_tr.logits, b_labels_tr)\n",
        "loss_tr"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0444, device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5z3vGIe5AeT",
        "outputId": "9da77a8c-1eab-4630-ee5f-bcbde5423592"
      },
      "source": [
        "#train\n",
        "total_eval_accuracy_tr = 0\n",
        "for i in range(len(predictions_tr)):\n",
        "  total_eval_accuracy_tr += flat_accuracy(predictions_tr[i], true_labels_tr[i])\n",
        "print(total_eval_accuracy_tr)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "318.52403846153845\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhXQy8SE5ojR",
        "outputId": "cd1c4fb0-863b-4393-b014-e52bb83fe9ae"
      },
      "source": [
        "#train\n",
        "avg_val_accuracy_tr = total_eval_accuracy_tr / len(train_dataloader)\n",
        "print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy_tr))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVlSAIDj5iZr",
        "outputId": "add2c4a4-f7e1-4b77-a7f6-461d915a58da"
      },
      "source": [
        "#train\n",
        "pred_flat_tr = np.argmax(predictions_tr[0], axis=1).flatten()\n",
        "labels_flat_tr = true_labels_tr[0].flatten()\n",
        "tot_ev_acc_tr = np.sum(pred_flat_tr == labels_flat_tr) / len(labels_flat_tr)\n",
        "print(tot_ev_acc_tr)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kH13fS46KiHq"
      },
      "source": [
        "Evaluating the train dataset with the model of max_length 99:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKvSUIUn80F3",
        "outputId": "0cae31e0-1a87-49ff-9a1a-2caa6bbc67ff"
      },
      "source": [
        "%%time\n",
        "# Put model in evaluation mode\n",
        "#model2.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions2_tr , true_labels2_tr = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in train_dataloader_99:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids_99_tr, b_input_mask_99_tr, b_labels_99_tr = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs_99_tr = model2(b_input_ids_99_tr, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask_99_tr)\n",
        "\n",
        "  logits_99_tr = outputs_99_tr[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits_99_tr = logits_99_tr.detach().cpu().numpy()\n",
        "  label_ids_99_tr = b_labels_99_tr.to('cpu').numpy()\n",
        "  \n",
        "\n",
        "#logits = logits[0].detach().cpu().numpy()\n",
        "\n",
        "  # Store predictions and true labels\n",
        "  predictions2_tr.append(logits_99_tr)\n",
        "  true_labels2_tr.append(label_ids_99_tr)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    DONE.\n",
            "CPU times: user 32.9 s, sys: 24.7 s, total: 57.5 s\n",
            "Wall time: 57.5 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CsFeCow9J5K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5d261f0-c16a-4bab-8d01-6235ee344d43"
      },
      "source": [
        "loss_99_tr = F.cross_entropy(outputs_99_tr.logits, b_labels_99_tr)\n",
        "loss_99_tr"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0334, device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZXgIIELQiVX",
        "outputId": "5b4bef40-2bdc-48ad-ee00-0dc8143b1dce"
      },
      "source": [
        "#test\n",
        "total_eval_accuracy_99_tr = 0\n",
        "for i in range(len(predictions2_tr)):\n",
        "  total_eval_accuracy_99_tr += flat_accuracy(predictions2_tr[i], true_labels2_tr[i])\n",
        "print(total_eval_accuracy_99_tr)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "320.375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNl8Hn4UQiVY",
        "outputId": "aa6a808c-eab2-483f-a1da-21a453f3843a"
      },
      "source": [
        "#test\n",
        "avg_val_accuracy_99_tr = total_eval_accuracy_99_tr / len(train_dataloader_99)\n",
        "print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy_99_tr))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.99\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UiL8GkqCQiVZ",
        "outputId": "4993bb4c-241a-47e4-acdd-59fb700aa50a"
      },
      "source": [
        "#test\n",
        "pred_flat2_tr = np.argmax(predictions2_tr[0], axis=1).flatten()\n",
        "labels_flat2_tr = true_labels2_tr[0].flatten()\n",
        "tot_ev_acc2_tr = np.sum(pred_flat2_tr == labels_flat2_tr) / len(labels_flat2_tr)\n",
        "print(tot_ev_acc2_tr)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24c9TqubP0pz"
      },
      "source": [
        "## Comparison of loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FHGkvllLgB7",
        "outputId": "82c649d7-431b-484c-a65e-4922a3ce7c73"
      },
      "source": [
        "if loss < loss_99:\n",
        "  if loss_tr < loss_99_tr:\n",
        "    print('the model 128 is better')\n",
        "  elif loss_tr > loss_99_tr:\n",
        "    print('its a tie')\n",
        "else:\n",
        "  print('the model 99 is better')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the model 99 is better\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEj4IpZWMgk1",
        "outputId": "335f93a5-8d9b-4566-b8b1-918cc3b5aca6"
      },
      "source": [
        "print('the difference (for the test set) between model 128 and model 99 is: ' + str(loss-loss_99))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the difference (for the test set) between model 128 and model 99 is: tensor(0.0022, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nTO3j9NMyNE",
        "outputId": "7ca00aa3-ed48-4dd9-b9a7-106cb51fd400"
      },
      "source": [
        "print('the difference (for the train set) between model 128 and model 99 is: ' + str(loss_tr-loss_99_tr))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the difference (for the train set) between model 128 and model 99 is: tensor(0.0111, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "Mhd-e1LrOpgn",
        "outputId": "72b8fcbc-5bdd-45e3-f1d6-a55204b68c0d"
      },
      "source": [
        "print('Stats of batch_size = 32 | max_length = 128 | epochs= 3')\n",
        "df3 = pd.read_pickle('/content/drive/MyDrive/Yelp/loss_accuracy_results_2df/stats_128_3e_32_')\n",
        "#df3[['Training Loss', 'Valid. Loss', 'Valid. Accur.']].apply(lambda x: round(x, 2))\n",
        "df3"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Stats of batch_size = 32 | max_length = 128 | epochs= 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.308592</td>\n",
              "      <td>0.274082</td>\n",
              "      <td>0.883384</td>\n",
              "      <td>0:03:50</td>\n",
              "      <td>0:00:20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.170174</td>\n",
              "      <td>0.244651</td>\n",
              "      <td>0.920351</td>\n",
              "      <td>0:03:50</td>\n",
              "      <td>0:00:20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.103651</td>\n",
              "      <td>0.271682</td>\n",
              "      <td>0.917302</td>\n",
              "      <td>0:03:50</td>\n",
              "      <td>0:00:20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1           0.308592     0.274082       0.883384       0:03:50         0:00:20\n",
              "2           0.170174     0.244651       0.920351       0:03:50         0:00:20\n",
              "3           0.103651     0.271682       0.917302       0:03:50         0:00:20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "bVThY_JiOuJ7",
        "outputId": "2b0b1a71-1c7f-40e2-e1f8-7ab19da4313b"
      },
      "source": [
        "print('Stats of batch_size = 32 | max_length = 99 | epochs= 3')\n",
        "df7 = pd.read_pickle('/content/drive/MyDrive/Yelp/loss_accuracy_results_2df/stats_99_3e_32')\n",
        "#df7[['Training Loss', 'Valid. Loss', 'Valid. Accur.']].apply(lambda x: round(x, 2))\n",
        "df7"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Stats of batch_size = 32 | max_length = 99 | epochs= 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.294424</td>\n",
              "      <td>0.318371</td>\n",
              "      <td>0.878430</td>\n",
              "      <td>0:03:17</td>\n",
              "      <td>0:00:17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.166630</td>\n",
              "      <td>0.231409</td>\n",
              "      <td>0.918826</td>\n",
              "      <td>0:03:20</td>\n",
              "      <td>0:00:17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.100725</td>\n",
              "      <td>0.312035</td>\n",
              "      <td>0.913491</td>\n",
              "      <td>0:03:19</td>\n",
              "      <td>0:00:18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1           0.294424     0.318371       0.878430       0:03:17         0:00:17\n",
              "2           0.166630     0.231409       0.918826       0:03:20         0:00:17\n",
              "3           0.100725     0.312035       0.913491       0:03:19         0:00:18"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "2PTfOi4OPDU_",
        "outputId": "d89bcfb4-deb9-4aa5-df46-fc6c5ec241de"
      },
      "source": [
        "average_loss_3e =[[128, 32]+ list(df3[['Training Loss', 'Valid. Loss', 'Valid. Accur.']].mean()),\n",
        "                  [99, 32] + list(df7[['Training Loss', 'Valid. Loss', 'Valid. Accur.']].mean())\n",
        "                  ]\n",
        "                  \n",
        "print('Comparison of loss and accuracy for the 3 epochs run:')\n",
        "loss_analysis_3e = pd.DataFrame(data=average_loss_3e, columns=['Max. Length', 'Batch Size', 'Training Loss', 'Valid. Loss', 'Valid. Accur.'])\n",
        "loss_analysis_3e"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Comparison of loss and accuracy for the 3 epochs run:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Max. Length</th>\n",
              "      <th>Batch Size</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>128</td>\n",
              "      <td>32</td>\n",
              "      <td>0.194139</td>\n",
              "      <td>0.263472</td>\n",
              "      <td>0.907012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>99</td>\n",
              "      <td>32</td>\n",
              "      <td>0.187260</td>\n",
              "      <td>0.287272</td>\n",
              "      <td>0.903582</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Max. Length  Batch Size  Training Loss  Valid. Loss  Valid. Accur.\n",
              "0          128          32       0.194139     0.263472       0.907012\n",
              "1           99          32       0.187260     0.287272       0.903582"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFFIIOqu722G"
      },
      "source": [
        "## Saving logits - pred labels.\n",
        "for both train and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1gho0OdhSqY",
        "outputId": "50bd90aa-093d-4792-d911-bdae432960b4"
      },
      "source": [
        "predictions2[0]"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3.0506377, -2.4544013],\n",
              "       [-2.1819134,  1.8736161],\n",
              "       [-3.0999944,  2.6844313],\n",
              "       [ 3.0060601, -2.3407938],\n",
              "       [ 3.1808267, -2.873114 ],\n",
              "       [-3.1453807,  2.7815762],\n",
              "       [-3.184499 ,  2.7352898],\n",
              "       [-2.7547746,  2.3747795],\n",
              "       [ 3.2465417, -2.8321352],\n",
              "       [ 3.3311489, -2.763662 ],\n",
              "       [ 3.1069078, -2.7008655],\n",
              "       [-3.3118598,  2.8378687],\n",
              "       [ 2.933878 , -2.4781406],\n",
              "       [-1.1789597,  1.0930814],\n",
              "       [-3.177808 ,  2.686439 ],\n",
              "       [-3.1957235,  2.7017624],\n",
              "       [ 2.6598947, -2.0953972],\n",
              "       [-3.0731606,  2.6333494],\n",
              "       [ 2.3621705, -1.8306882],\n",
              "       [-3.0769148,  2.5526905],\n",
              "       [ 2.9885793, -2.500867 ],\n",
              "       [-3.1877484,  2.7369823],\n",
              "       [ 2.6635275, -2.1782904],\n",
              "       [-3.1373687,  2.8639278],\n",
              "       [ 2.7181003, -2.0343425],\n",
              "       [-2.9361038,  2.3863578],\n",
              "       [-1.355257 ,  1.2916147],\n",
              "       [ 3.076884 , -2.6558518],\n",
              "       [ 3.0625947, -2.7086399],\n",
              "       [ 3.181285 , -2.6442196],\n",
              "       [-3.3451715,  2.785516 ],\n",
              "       [-2.9900498,  2.4726944]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPLShgPx1jp4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f368b08-7442-4484-9f6d-f3eee8f72398"
      },
      "source": [
        "# for the model 99\n",
        "logits_test2 = [list(np.argmax(predictions2[p], axis=1).flatten()) for p in range(len(predictions2))]\n",
        "print('length of the test predictions: ' + str(len(logits_test2)))\n",
        "# converting the list of lists into a single list\n",
        "bert_test_labels = [label for l in logits_test2 for label in l]\n",
        "print('number of predicted labels: ' + str(len(bert_test_labels)))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "length of the test predictions: 82\n",
            "number of predicted labels: 2599\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dn7GQBd86sV8",
        "outputId": "6f922f04-6071-4cdd-9e67-e593bd452974"
      },
      "source": [
        "# for the model 128\n",
        "logits_test = [list(np.argmax(predictions[p], axis=1).flatten()) for p in range(len(predictions))]\n",
        "print(len(logits_test))\n",
        "# converting the list of lists into a single list\n",
        "bert_test_labels_128 = [label for l in logits_test for label in l]\n",
        "print(len(bert_test_labels_128))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "82\n",
            "2599\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnLJjGdkSmqT",
        "outputId": "201fdd10-65bc-4110-a5b1-2de5875645dd"
      },
      "source": [
        "# for the model 99\n",
        "logits_train2 = [list(np.argmax(predictions2_tr[p], axis=1).flatten()) for p in range(len(predictions2_tr))]\n",
        "print('length of the train predictions: ' + str(len(logits_train2)))\n",
        "# converting the list of lists into a single list\n",
        "bert_train_labels = [label for l in logits_train2 for label in l]\n",
        "print('number of predicted labels: ' + str(len(bert_train_labels)))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "length of the train predictions: 325\n",
            "number of predicted labels: 10394\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQ3HQ60f651s",
        "outputId": "4a69221b-b862-47e0-d441-43c88714600c"
      },
      "source": [
        "# for the model 128\n",
        "logits_train = [list(np.argmax(predictions_tr[p], axis=1).flatten()) for p in range(len(predictions_tr))]\n",
        "print(len(logits_train))\n",
        "bert_train_labels_128 = [label for l in logits_train for label in l]\n",
        "print(len(bert_train_labels_128))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "325\n",
            "10394\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pQ8UvUXRcXh"
      },
      "source": [
        "### Comparing the logits obtain during training to the ones obtain here:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaRRRexT_D4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcc322fb-e0b1-4e30-c06e-3ebd12ef72d0"
      },
      "source": [
        "logits_val_3e = torch.load('/content/drive/MyDrive/Yelp/model_128/logits_val_3e')\n",
        "print(len(logits_val_3e))\n",
        "logits_train_3e = torch.load( '/content/drive/MyDrive/Yelp/model_128/logits_train_3e')\n",
        "print(len(logits_train_3e))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "246\n",
            "975\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVCzju1M7hYt",
        "outputId": "874b9d55-d16e-4b1d-a4c0-0fab428112e1"
      },
      "source": [
        "bert_test_labels[0:7]"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 1, 0, 0, 1, 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51M1Ybz8Uyeo",
        "outputId": "b6e6000c-cf7b-41ed-fbc0-ffa9e2fb5c17"
      },
      "source": [
        "len(logits_val_3e[0])"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rWItndXU57I",
        "outputId": "ec5c7e0c-fe70-4a0d-e7dd-396d5e273b04"
      },
      "source": [
        "32*24"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7840"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WT-rffDV_k_2",
        "outputId": "fa6fa844-fabd-4f13-c0bd-5045cde247bb"
      },
      "source": [
        "labels_test_3e = logits_val_3e[164:]\n",
        "labels_test_3e = np.concatenate(labels_test_3e, axis=0)\n",
        "labels_test_3e[0:7]"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 0, 0, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjdCSLat9VuD",
        "outputId": "b08f9397-f0a4-40dd-c0d2-553dd638fdce"
      },
      "source": [
        "flat_true_labels[20:33]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcAs4hFV7r5T",
        "outputId": "32ae1636-18c7-4eee-8979-c559e3c3a3a0"
      },
      "source": [
        "bert_train_labels[0:7]"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 0, 0, 1, 1, 1, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcAzr6yKAV7H",
        "outputId": "5c4b632a-c411-439f-c538-a7b0f71203ed"
      },
      "source": [
        "labels_train_3e = logits_train_3e[650:]\n",
        "labels_train_3e = np.concatenate(labels_train_3e, axis=0)\n",
        "labels_train_3e[0:7]"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, 0, 0, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbkK5LjI9vBn",
        "outputId": "2bf758a7-9b28-4a81-c373-2544972d1f82"
      },
      "source": [
        "flat_true_labels_tr = np.concatenate(true_labels_tr, axis=0)\n",
        "flat_true_labels_tr[0:7]"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 1, 1, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sW_r8Yq8BHzI"
      },
      "source": [
        "The things above are to check if the train predictions obtain here are the same as the 3rd epoch. \n",
        "\n",
        "Spoiler: no they are not the same"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXQy4Pq6hjch"
      },
      "source": [
        "torch.save(bert_train_labels, '/content/drive/MyDrive/Yelp/model_99/flat_pred_labels_train')\n",
        "torch.save(bert_test_labels, '/content/drive/MyDrive/Yelp/model_99/flat_pred_labels_test')\n",
        "\n",
        "torch.save(bert_train_labels_128, '/content/drive/MyDrive/Yelp/model_128/flat_pred_labels_train')\n",
        "torch.save(bert_test_labels_128, '/content/drive/MyDrive/Yelp/model_128/flat_pred_labels_test')"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwQzlm6D4gja"
      },
      "source": [
        "## Matthews Corr Coef"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCYgK9lK5vaj",
        "outputId": "187904a9-9d6c-4db6-a2e8-764759e1cc45"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "  \n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  \n",
        "  # Calculate and store the coef for this batch.  \n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
        "  matthews_set.append(matthews)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "owhE-rVe6Chi",
        "outputId": "b8f482be-97e4-4de1-a54e-e0812156e49f"
      },
      "source": [
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Create a barplot showing the MCC score for each batch of test samples.\n",
        "ax = sns.barplot(x=list(range(len(matthews_set))), y=matthews_set, ci=None)\n",
        "\n",
        "plt.title('MCC Score per Batch')\n",
        "plt.ylabel('MCC Score (-1 to +1)')\n",
        "plt.xlabel('Batch #')\n",
        "# change the x axis labels so its readable\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JieYlTdy6HsK",
        "outputId": "df18a511-fbbf-4526-f231-c91815a08283"
      },
      "source": [
        "# Combine the results across all batches. \n",
        "#flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "# For each sample, pick the label (0 or 1) with the higher score.\n",
        "#flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "flat_predictions = bert_test_labels.copy()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('Total MCC: %.3f' % mcc)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total MCC: 0.833\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YAQ7HtH27K1"
      },
      "source": [
        "# Trying with new sentences/ reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnZCv7Kb-cy-"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('/content/drive/MyDrive/Yelp/model_99/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dw6FdkO56YR7"
      },
      "source": [
        "review_example = 'Very friendly and helpful staff. Increasing my Dutch vocabulary during commute thanks to a great suggestion.'\n",
        "\n",
        "positive_review ='A truly inspiring venue. Friendly, helpful staff. Amazing portraits and awesome surroundings.  Hope to go back sometime soon'\n",
        "#'Great set up. Very good food. Luxury Bar surroundings. Good food but quite pricey. Staff are polite & very helpful. They all look smart.'\n",
        "\n",
        "\n",
        "#'Terrible customer service downstairs within the kitchen appliances department.'\n",
        "negative_review = 'Completely appalled by the lack of assistance or help I received in trying to resolve an issue with an TV that has now been going on for a month. Staff appeared disinterested and unhelpful, despite me explaining I have spent in excess of five hours on hold trying to speak to someone about the resolution of the issue. There is no clarity of who to speak to, no one seems to know what is going on, and no one knows what the resolution is. I appreciate these are challenging times but I and have had no communication in any form from the company, I am the one who appears to doing all the leg work, even having to speak to the repair contractors in person to find out what is happening! Terrible service, terrible aftercare, terrible communication - would seriously advise against making any large electrical purchases from the company.'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gO-y1nO2-WY2"
      },
      "source": [
        "## the real test\n",
        "Remember only 2 labels: 0=negative, 1=positive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACwttPA5-jdo"
      },
      "source": [
        "def encode(sequence):\n",
        "  \"\"\"\n",
        "  The copied version was:\n",
        "    return tokenizer.encode_plus(\n",
        "                sequence,\n",
        "                add_special_tokens=True,\n",
        "                max_length= 150,\n",
        "                return_token_type_ids=False,\n",
        "                padding = 'max_length',\n",
        "                return_attention_mask = True,\n",
        "                return_tensors = 'pt',\n",
        "                truncation = True\n",
        "    )\n",
        "  \"\"\" \n",
        "  return tokenizer.encode_plus(sequence, return_token_type_ids=False, return_tensors = 'pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIf8jtdI-lU9"
      },
      "source": [
        "def predict(sequence='I love you a lot. You are really great. You are wonderful and awesome.'):\n",
        "    encoded = encode(sequence)\n",
        "    encoded_ids = encoded['input_ids'].to(device)\n",
        "    enconded_attention = encoded['attention_mask'].to(device)\n",
        "    with torch.no_grad():\n",
        "        output = model(encoded_ids, attention_mask=enconded_attention)[0]\n",
        "        output = output.detach().cpu().numpy()\n",
        "        pred_flat = np.argmax(output, axis=1).flatten()\n",
        "        #sig_factor = torch.sigmoid(output) / torch.sigmoid(output).sum()\n",
        "        #return {'proportional':  sig_factor.numpy().tolist(), 'sigmoid': torch.sigmoid(output).numpy().tolist(), 'stars': pred_flat.item() + 1, 'raw': output.numpy().tolist()}\n",
        "        return {'label': pred_flat.item()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAxs9fvE9o0p",
        "outputId": "dbda2a70-8aa2-4f2a-b12e-5f5056c56a33"
      },
      "source": [
        "predict(review_example)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzElqB-0eIS1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6gGGa7V_aNE"
      },
      "source": [
        "# Converting input ids back to words:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owuuEvGwxTO_",
        "outputId": "b91abe96-c82b-449f-c5a5-b66fba056833"
      },
      "source": [
        "test_df = pd.read_pickle('/content/drive/MyDrive/Yelp/sample_test_2599.pkl')\n",
        "test_df.reset_index(drop=True, inplace=True)\n",
        "test_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2599, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "UiXTYyOHDSZu",
        "outputId": "6f943a1f-2c10-4f4c-cd9e-ec6a0614f7c6"
      },
      "source": [
        "test_df.text[2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'walked uncle saturday help cpap machine met respiratory therapist gentleman named juan helpful explained uncle needed use machine knowledgeable uncle condition able answer questions showed machine works clean patient came choosing mask polite friendly thanks juan experience pleasant'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1WsA5USBRyw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c08f7b6-551a-4cf5-fc64-d1d89e44f7e5"
      },
      "source": [
        "test_ids[2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[101,\n",
              " 2939,\n",
              " 4470,\n",
              " 5095,\n",
              " 2393,\n",
              " 18133,\n",
              " 9331,\n",
              " 3698,\n",
              " 2777,\n",
              " 16464,\n",
              " 19294,\n",
              " 10170,\n",
              " 2315,\n",
              " 5348,\n",
              " 14044,\n",
              " 4541,\n",
              " 4470,\n",
              " 2734,\n",
              " 2224,\n",
              " 3698,\n",
              " 3716,\n",
              " 3085,\n",
              " 4470,\n",
              " 4650,\n",
              " 2583,\n",
              " 3437,\n",
              " 3980,\n",
              " 3662,\n",
              " 3698,\n",
              " 2573,\n",
              " 4550,\n",
              " 5776,\n",
              " 2234,\n",
              " 10549,\n",
              " 7308,\n",
              " 13205,\n",
              " 5379,\n",
              " 4283,\n",
              " 5348,\n",
              " 3325,\n",
              " 8242,\n",
              " 102,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCgo5ufAJwO8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "92400190-1e80-44a4-d030-67e6f25876d3"
      },
      "source": [
        "list(tokenizer.vocab.keys())[2939]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'walked'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "6U7L9FcXDF3j",
        "outputId": "417e27e8-169a-4276-8e9b-485189cc6ce7"
      },
      "source": [
        "tokenizer.decode(test_dataset[2][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[CLS] walked uncle saturday help cpap machine met respiratory therapist gentleman named juan helpful explained uncle needed use machine knowledgeable uncle condition able answer questions showed machine works clean patient came choosing mask polite friendly thanks juan experience pleasant [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66fHiRJzDxhe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}