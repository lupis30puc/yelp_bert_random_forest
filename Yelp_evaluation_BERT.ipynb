{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Yelp-evaluation_BERT.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNRrulqZ9H0FwXUSGWM3olI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lupis30puc/yelp_bert_random_forest/blob/lupis30puc-update-3/Yelp_evaluation_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfFofRq00h1v"
      },
      "source": [
        "# Set Up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJD0FGBS0ghp",
        "outputId": "15e51d32-760e-4d6d-9d98-45fde13537fd"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/0c/7d5950fcd80b029be0a8891727ba21e0cd27692c407c51261c3c921f6da3/transformers-4.1.1-py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 7.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 29.1MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 41.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=43fb69942afb01ea07ddc35789670b62c0522ed898768e84ed0f6e64174ae87d\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fJjJCGQ0lVf"
      },
      "source": [
        "## GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfLHT8dI0qQQ",
        "outputId": "6ffc3af1-8e55-4b0b-9630-1466e14ed142"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWxJt3i20tLd",
        "outputId": "ce84b9dd-d4b3-428c-ef0a-5fe58e21b7c8"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9QoEyD40yWw"
      },
      "source": [
        "## Loading the tensors dataset and model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3H3o99g0vn4",
        "outputId": "006bca00-6140-4bcc-d062-15a13e59021f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBCut10VzcJj"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "import time"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xU8egMBY1A6Q"
      },
      "source": [
        "test_dataset = torch.load('/content/drive/MyDrive/Yelp/sample_yelp_tensors/_test_150')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvA9mRKx1yMx",
        "outputId": "24479a78-4210-4ead-85c5-573cc7adcde4"
      },
      "source": [
        "test_dataset[0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([  101,  2044,  3752,  2035,  1996,  2307,  4391,  2057,  2245,  2057,\n",
              "          1040,  2507,  4012, 15455,  6072,  1037,  3046,  2005,  6265,  2057,\n",
              "          4694,  1056,  9364,  2057,  2179,  1996, 25545,  2465,  2100,  2007,\n",
              "          3737, 23127,  4406,  2070,  2060,  5171,  4916,  7884,  2057,  2020,\n",
              "         11188, 22775,  1998,  3491,  2000,  1037,  3332,  9065, 11772,  2048,\n",
              "          4127,  1997, 26509,  2020,  5359, 13364,  1996, 12183,  2038,  2172,\n",
              "          2000,  5454,  2013,  1045,  4900,  1996,  6265,  2569,  2007,  1037,\n",
              "          3601,  1997,  2048,  3760,  4372, 13334,  2015,  1996, 26192,  2094,\n",
              "          7975,  4372,  5428, 27266,  2050,  2007, 16709, 12901,  2001,  6581,\n",
              "          2021,  2130,  2488,  2001,  1996,  7975,  9610,  7712, 18003,  2050,\n",
              "          2009,  2001,  5642,  2011,  3903,  1997,  5785,  1998,  2128, 13017,\n",
              "         13435,  2673,  2790,  4840,  1998, 25628,  1996,  4825,  2003, 21121,\n",
              "          2011,  1045,  2903,  2155,  2372,  2013,  3290,  2877,  2000,  2026,\n",
              "          2069,  4997,  7615,  2045,  2001,  1037,  7263,  2653,  8803, 20888,\n",
              "          2256,  2344,  2035,  1999,  2035,  1037,  3737,  6265,  3325,   102]),\n",
              " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1]),\n",
              " tensor(1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zn4lFOdd10m0"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "# batch size\n",
        "batch_size = 32\n",
        "\n",
        "prediction_sampler = SequentialSampler(test_dataset)\n",
        "prediction_dataloader = DataLoader(test_dataset, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_HVuNEW2Hld",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6cc7d8e-3427-4859-bd7b-0db408f2c055"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "device = torch.device(\"cuda\")\n",
        "#model = TheModelClass(*args, **kwargs)\n",
        "\"\"\"\n",
        "model = BertForSequenceClassification(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\"\"\"\n",
        "model = torch.load('/content/drive/MyDrive/Yelp/model_save3/model-08-JAN_150', map_location=\"cuda:0\")  # Choose whatever GPU device number you want\n",
        "model.to(device)\n",
        "# Make sure to call input = input.to(device) on any input tensors that you feed to the model\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epOKQge4_JHw"
      },
      "source": [
        "# Evaluating the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBgU8-q048iy",
        "outputId": "888d3b24-34f0-4c36-c9b4-c548d0fcbd1d"
      },
      "source": [
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "\n",
        "#logits = logits[0].detach().cpu().numpy()\n",
        "\n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87L9jZ42ty7a"
      },
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "    #np.argmax(logits, axis=1).flatten()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nt12q-Pzu-dz",
        "outputId": "a563ea5e-f865-4ea2-b3ff-eb4360a266e7"
      },
      "source": [
        "total_eval_accuracy = 0\n",
        "for i in range(len(predictions)):\n",
        "  total_eval_accuracy += flat_accuracy(predictions[i], true_labels[i])\n",
        "print(total_eval_accuracy)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20.03125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZevst2b0Goo",
        "outputId": "f644d855-88be-4e5f-9284-a9efa72956ba"
      },
      "source": [
        "avg_val_accuracy = total_eval_accuracy / len(prediction_dataloader)\n",
        "print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSj0Y1-Hzp0u",
        "outputId": "0bc599d3-8fe3-4de9-af48-8016753d948d"
      },
      "source": [
        "pred_flat = np.argmax(predictions[0], axis=1).flatten()\n",
        "labels_flat = true_labels[0].flatten()\n",
        "tot_ev_acc = np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "print(tot_ev_acc)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwQzlm6D4gja"
      },
      "source": [
        "## Matthews Corr Coef"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCYgK9lK5vaj",
        "outputId": "21061f22-5a10-46e8-9194-0c73f379e0e4"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "  \n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  \n",
        "  # Calculate and store the coef for this batch.  \n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
        "  matthews_set.append(matthews)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "owhE-rVe6Chi",
        "outputId": "10872aee-e5de-4ea8-ad32-4a55ef6d1c5b"
      },
      "source": [
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Create a barplot showing the MCC score for each batch of test samples.\n",
        "ax = sns.barplot(x=list(range(len(matthews_set))), y=matthews_set, ci=None)\n",
        "\n",
        "plt.title('MCC Score per Batch')\n",
        "plt.ylabel('MCC Score (-1 to +1)')\n",
        "plt.xlabel('Batch #')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JieYlTdy6HsK",
        "outputId": "4b2879e4-2a72-442a-c2f8-f4119e563b2e"
      },
      "source": [
        "# Combine the results across all batches. \n",
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "# For each sample, pick the label (0 or 1) with the higher score.\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('Total MCC: %.3f' % mcc)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total MCC: 0.905\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YAQ7HtH27K1"
      },
      "source": [
        "# Trying with new sentences/ reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnZCv7Kb-cy-"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('/content/drive/MyDrive/Yelp/model_save3/')\n",
        "#tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dw6FdkO56YR7"
      },
      "source": [
        "review_example = 'Very friendly and helpful staff. Increasing my Dutch vocabulary during commute thanks to a great suggestion.'\n",
        "\n",
        "#'A truly inspiring venue. Friendly, helpful staff. Amazing portraits and awesome surroundings.  Hope to go back sometime soon'\n",
        "#'Great set up. Very good food. Luxury Bar surroundings. Good food but quite pricey. Staff are polite & very helpful. They all look smart.'\n",
        "\n",
        "\n",
        "#'Terrible customer service downstairs within the kitchen appliances department.'\n",
        "negative_review = 'Completely appalled by the lack of assistance or help I received in trying to resolve an issue with an TV that has now been going on for a month. Staff appeared disinterested and unhelpful, despite me explaining I have spent in excess of five hours on hold trying to speak to someone about the resolution of the issue. There is no clarity of who to speak to, no one seems to know what is going on, and no one knows what the resolution is. I appreciate these are challenging times but I and have had no communication in any form from the company, I am the one who appears to doing all the leg work, even having to speak to the repair contractors in person to find out what is happening! Terrible service, terrible aftercare, terrible communication - would seriously advise against making any large electrical purchases from the company.'"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5itHEcl3-RRy"
      },
      "source": [
        "## experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZX0qMNRd2_iM",
        "outputId": "f79b868c-b1bc-4f29-fcc4-3232795b60a9"
      },
      "source": [
        "example_tokens = tokenizer.encode_plus(review_example, return_token_type_ids=False, return_tensors = 'pt')\n",
        "example_tokens"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  101,  2200,  5379,  1998, 14044,  3095,  1012,  4852,  2026,  3803,\n",
              "         16188,  2076,  4012, 26746,  4283,  2000,  1037,  2307, 10293,  1012,\n",
              "           102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEZZBDfD4MuK",
        "outputId": "df9e2d16-5dcf-4241-a8b8-e4295f3707d8"
      },
      "source": [
        "len(example_tokens['input_ids'])"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TllhIzU4Mlz",
        "outputId": "1973cc7a-c31d-411e-f2f1-86f9bcc2c3da"
      },
      "source": [
        "example_tokens['attention_mask']"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZS21B5G4vrR"
      },
      "source": [
        " # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwyf2sSE7F1m"
      },
      "source": [
        "example_attention = example_tokens['attention_mask'].to(device)"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gUIiko98MxF"
      },
      "source": [
        "example_ids = example_tokens['input_ids'].to(device)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "008GNcWr3lVm",
        "outputId": "343bc60f-374a-4cc5-863b-229d9e9d8fd4"
      },
      "source": [
        " with torch.no_grad():\n",
        "   #output = model(example_tokens['input_ids'], attention_mask=example_tokens['attention_mask'])[0]\n",
        "   output = model(example_ids, attention_mask=example_attention)[0]\n",
        "output = output.detach().cpu().numpy()\n",
        "pred_flat = np.argmax(output, axis=1).flatten()\n",
        "print('label')\n",
        "print(pred_flat.item())"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gO-y1nO2-WY2"
      },
      "source": [
        "## the real test\n",
        "Remember only 2 labels: 0=negative, 1=positive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACwttPA5-jdo"
      },
      "source": [
        "def encode(sequence):\n",
        "  \"\"\"\n",
        "  The copied version was:\n",
        "    return tokenizer.encode_plus(\n",
        "                sequence,\n",
        "                add_special_tokens=True,\n",
        "                max_length= 150,\n",
        "                return_token_type_ids=False,\n",
        "                padding = 'max_length',\n",
        "                return_attention_mask = True,\n",
        "                return_tensors = 'pt',\n",
        "                truncation = True\n",
        "    )\n",
        "  \"\"\" \n",
        "  return tokenizer.encode_plus(sequence, return_token_type_ids=False, return_tensors = 'pt')"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIf8jtdI-lU9"
      },
      "source": [
        "def predict(sequence='I love you a lot. You are really great. You are wonderful and awesome.'):\n",
        "    encoded = encode(sequence)\n",
        "    encoded_ids = encoded['input_ids'].to(device)\n",
        "    enconded_attention = encoded['attention_mask'].to(device)\n",
        "    with torch.no_grad():\n",
        "        output = model(encoded_ids, attention_mask=enconded_attention)[0]\n",
        "        output = output.detach().cpu().numpy()\n",
        "        pred_flat = np.argmax(output, axis=1).flatten()\n",
        "        #sig_factor = torch.sigmoid(output) / torch.sigmoid(output).sum()\n",
        "        #return {'proportional':  sig_factor.numpy().tolist(), 'sigmoid': torch.sigmoid(output).numpy().tolist(), 'stars': pred_flat.item() + 1, 'raw': output.numpy().tolist()}\n",
        "        return {'label': pred_flat.item()}"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAxs9fvE9o0p",
        "outputId": "f66e3989-483f-44e3-f2f4-f1ef8532525f"
      },
      "source": [
        "predict(negative_review)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6gGGa7V_aNE"
      },
      "source": [
        "# Converting input ids back to words:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owuuEvGwxTO_",
        "outputId": "2ac4746d-9087-48ab-997e-940a7409e3c7"
      },
      "source": [
        "test_df = pd.read_pickle('/content/drive/MyDrive/Yelp/sample_test_650.pkl')\n",
        "test_df.reset_index(drop=True, inplace=True)\n",
        "test_df.shape"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(650, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "UiXTYyOHDSZu",
        "outputId": "0fc4982e-1309-4607-cd1a-63c39d0d29b4"
      },
      "source": [
        "test_df.text[2]"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'very clean hotel jacuzzi is very huge shower and bathroom are huge and clean view was nice although it was the back of the hotel lobby was nice and valet was great now the bad tv kept freezing every few hours for several minutes at a time we were on the th floor and heard the train every night all thruout the night loud and clearly im a freight train engineer for u p and thats the last thing i want waking me up away from work so that makes nights of broken sleep all night never good i would not stay here again as we all know in vegas most people are in their hotel only to sleep '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCgo5ufAJwO8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "72769d30-b59a-463b-e6d0-b045c32df4be"
      },
      "source": [
        "list(tokenizer.vocab.keys())[2044]"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'after'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1WsA5USBRyw"
      },
      "source": [
        "review_test = test_dataset[0][0]"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "6U7L9FcXDF3j",
        "outputId": "f4a5ba30-d6db-425a-8d7d-f79d24dabb82"
      },
      "source": [
        "tokenizer.decode(test_dataset[2][0])"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[CLS] very clean hotel jacuzzi is very huge shower and bathroom are huge and clean view was nice although it was the back of the hotel lobby was nice and valet was great now the bad tv kept freezing every few hours for several minutes at a time we were on the th floor and heard the train every night all thruout the night loud and clearly im a freight train engineer for u p and thats the last thing i want waking me up away from work so that makes nights of broken sleep all night never good i would not stay here again as we all know in vegas most people are in their hotel only to sleep [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66fHiRJzDxhe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}